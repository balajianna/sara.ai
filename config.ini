; Description: Configuration file for the LSTM model
[DATA]
directory = data
time_window = 60
num_subjects = 50
samples_per_subject = 120
validation_split = 0.20
random_state = 42

[TRAINING]
epochs = 50
batch_size = 32
threshold = 0.00005
dropout_rate = 0.3
lstm_layers = [128, 64, 32]
early_stopping_patience = 10
reduce_lr_patience = 5
learning_rate = 0.001
optimizer = adam
loss = mse
metrics = mae
dense_unit = 16
activation = relu

[HYPER]
use_hyperparameter_tuning = True
number_of_subjects_for_parameter_tuning = 5
samples_per_subject_for_parameter_tuning = 30
epochs_for_parameter_tuning = 10
batch_size_for_parameter_tuning = 32
number_of_trials_for_parameter_tuning = 10

[MODEL]
keras_model_path = output/lstm_model_20241117_03.keras
scaler_path = output/scaler_20241117_03.joblib

[LOG]
log_path = output/log_20241117_03.log
output_dir = output
debug = True

[PREDICT]
subject_idS = 11, 38
