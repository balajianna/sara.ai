; Description: Configuration file for the LSTM model
[DATA]
directory = data
time_window = 60
num_subjects = 10
validation_split = 0.2
random_state = 42

[TRAINING]
epochs = 10
batch_size = 32
threshold = 0.00005
dropout_rate = 0.3
lstm_layers = [128, 64, 32]
early_stopping_patience = 10
reduce_lr_patience = 5
learning_rate = 0.001
optimizer = adam
loss = mse
metrics = mae
dense_unit = 16
activation = relu

[HYPER]
use_hyperparameter_tuning = True
number_of_subjects_for_parameter_tuning = 5
samples_per_subject_for_parameter_tuning = 30
epochs_for_parameter_tuning = 10
batch_size_for_parameter_tuning = 32
number_of_trials_for_parameter_tuning = 10

[MODEL]
keras_model_path = lstm_model_20241116_milestone.keras
scaler_path = scaler_20241116_milestone.joblib
h5_model_path = lstm_model_20241116_milestone.h5

[LOG]
log_path = log_20241116_milestone.log
debug = True

[PREDICT]
subject_idS = 31, 38
