2024-11-15 14:10:02,205 - INFO - LSTM model summary:
2024-11-15 14:10:02,207 - INFO - Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                          │ (None, 60, 64)              │          16,896 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 60, 64)              │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 60, 64)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_1 (LSTM)                        │ (None, 32)                  │          12,416 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 32)                  │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │             528 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 1)                   │              17 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 30,241 (118.13 KB)
 Trainable params: 30,049 (117.38 KB)
 Non-trainable params: 192 (768.00 B)

2024-11-15 14:10:02,207 - INFO - Preprocessing data for 1 subjects...
2024-11-15 14:10:03,497 - INFO - Data shapes - Train: (108713, 60), Val: (27179, 60)
2024-11-15 14:10:03,498 - INFO - Configuration: {'epochs': 2, 'batch_size': 64, 'lstm_layers': [128, 64, 32], 'dropout_rate': 0.3, 'early_stopping_patience': 10, 'reduce_lr_patience': 5, 'threshold': 10.0}
2024-11-15 14:10:03,498 - INFO - Training LSTM model...
2024-11-15 14:10:03,498 - INFO - Training data shapes - X: (108713, 60, 1), y: (108713,)
2024-11-15 14:10:03,498 - INFO - Validation data shapes - X: (27179, 60, 1), y: (27179,)
2024-11-15 14:10:03,529 - INFO - LSTM model summary:
2024-11-15 14:10:03,532 - INFO - Model: "sequential_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm_2 (LSTM)                        │ (None, 60, 128)             │          66,560 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_2                │ (None, 60, 128)             │             512 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 60, 128)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_3 (LSTM)                        │ (None, 60, 64)              │          49,408 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_3                │ (None, 60, 64)              │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 60, 64)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_4 (LSTM)                        │ (None, 32)                  │          12,416 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_4                │ (None, 32)                  │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_2 (Dense)                      │ (None, 16)                  │             528 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_3 (Dense)                      │ (None, 1)                   │              17 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 129,825 (507.13 KB)
 Trainable params: 129,377 (505.38 KB)
 Non-trainable params: 448 (1.75 KB)

2024-11-15 14:13:50,974 - INFO - Loss plot saved as lstm_loss_20241115_141350.png
2024-11-15 14:13:50,975 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2024-11-15 14:13:50,986 - INFO - Model saved as lstm_model_20241115_141350.h5
2024-11-15 14:13:51,040 - INFO - Loss plot saved as lstm_loss_20241115_141350.png
2024-11-15 14:13:51,055 - INFO - Model saved as lstm_model_20241115_141351.keras
2024-11-15 14:13:51,055 - INFO - Scaler saved as scaler_20241115_141351.joblib
2024-11-15 14:13:51,265 - ERROR - Error making prediction: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.
