2024-11-15 19:20:24,537 - INFO - Preprocessing data for 1 subjects...
2024-11-15 19:20:26,084 - INFO - Data shapes - Train: (108713, 60), Val: (27179, 60)
2024-11-15 19:20:26,084 - INFO - Configuration: {'epochs': 2, 'batch_size': 32, 'lstm_layers': [128, 64, 32], 'dropout_rate': 0.3, 'early_stopping_patience': 10, 'reduce_lr_patience': 5, 'threshold': 5e-05}
2024-11-15 19:20:26,084 - INFO - Training LSTM model...
2024-11-15 19:20:26,084 - INFO - Training data shapes - X: (108713, 60, 1), y: (108713,)
2024-11-15 19:20:26,084 - INFO - Validation data shapes - X: (27179, 60, 1), y: (27179,)
2024-11-15 19:20:26,136 - INFO - LSTM model summary:
2024-11-15 19:20:26,139 - INFO - Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                          │ (None, 60, 128)             │          66,560 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 60, 128)             │             512 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 60, 128)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_1 (LSTM)                        │ (None, 60, 64)              │          49,408 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 60, 64)              │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 60, 64)              │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_2 (LSTM)                        │ (None, 32)                  │          12,416 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_2                │ (None, 32)                  │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │             528 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 1)                   │              17 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 129,825 (507.13 KB)
 Trainable params: 129,377 (505.38 KB)
 Non-trainable params: 448 (1.75 KB)

2024-11-15 19:29:40,070 - INFO - Loss plot saved as lstm_loss_20241115_192939.png
2024-11-15 19:29:40,071 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2024-11-15 19:29:40,085 - INFO - Model saved as lstm_model_20241115_1915.h5
2024-11-15 19:29:40,138 - INFO - Loss plot saved as lstm_loss_20241115_192940.png
2024-11-15 19:29:40,153 - INFO - Model saved as lstm_model_20241115_1915.keras
2024-11-15 19:29:40,154 - INFO - Scaler saved as scaler_20241115_1915.joblib
